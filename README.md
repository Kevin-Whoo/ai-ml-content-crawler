# ğŸ¤– AI/ML Content Crawler

An intelligent web crawler that gathers the latest AI/ML research papers, blog posts, and repository updates from major sources.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Run the crawler (choose one):
# Option 1: As a module
python -m src

# Option 2: After installing with pip
pip install -e .
ai-ml-crawler
```

## ğŸ“ Project Structure

```
ai-ml-content-crawler/
â”œâ”€â”€ pyproject.toml         # Project configuration
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ src/                   # Source code (ai_ml_crawler package)
â”‚   â”œâ”€â”€ __main__.py       # Module entry point
â”‚   â”œâ”€â”€ cli.py            # CLI entry point
â”‚   â”œâ”€â”€ main.py           # Main crawler logic
â”‚   â”œâ”€â”€ config.py         # Configuration settings
â”‚   â”œâ”€â”€ crawlers/         # Individual crawler modules
â”‚   â””â”€â”€ utils/            # Utility modules
â”œâ”€â”€ docs/                 # Documentation
â”‚   â”œâ”€â”€ README.md         # Detailed documentation
â”‚   â”œâ”€â”€ USAGE_GUIDE.md    # Usage instructions
â”‚   â”œâ”€â”€ SECURITY.md       # Security guidelines
â”‚   â””â”€â”€ analysis/         # Analysis reports
â”œâ”€â”€ output/               # Generated reports
â”œâ”€â”€ cache/                # Cached web content
â””â”€â”€ .env.example          # Environment variables template
```

## ğŸ“Š Features

- **8 Active Crawlers**: OpenAI, Meta, Anthropic, GitHub, ArXiv, Google Scholar, Medium, HuggingFace
- **Smart Caching**: 15-day TTL for efficient performance
- **Content Filtering**: AI/ML relevance scoring
- **Multiple Output Formats**: Markdown reports with metadata
- **Anti-Detection**: Browser profiles and rate limiting
- **Async Processing**: Concurrent crawler execution

## ğŸ“„ Latest Output

Check the `output/` directory for the most recent AI/ML resources report.

For detailed documentation, see `docs/README.md`.
